---
title: "Challenge_2"
format: html
editor: visual
---

***Challenge 2***

```{r}
#Step 1
library(tidyverse)


url <- "https://raw.githubusercontent.com/difiore/ada-datasets/main/zombies.csv"

z <- read_csv(url)

glimpse(z)    
head(z)      
summary(z)    



colnames(z)
```

#Step 2

```{r}

numeric_cols <- z %>%
  select(where(is.numeric)) %>%
  select(-id) %>%  
  colnames()

z_summary <- z %>%
  summarize(across(all_of(numeric_cols), list(
    mean = ~mean(.x, na.rm = TRUE),
    sd = ~sqrt(sum((.x - mean(.x, na.rm = TRUE))^2, na.rm = TRUE) / n())
  ), .names = "{.col}_{.fn}"))

print(z_summary)

```

\***Step 3**

```{r}

numeric_cols <- z %>%
  select(where(is.numeric)) %>%
  colnames()

for (var in numeric_cols) {
  p <- ggplot(z, aes(x = gender, y = .data[[var]], fill = gender)) +
    geom_boxplot() +
    labs(title = paste("Boxplot of", var, "by Gender"),
         x = "Gender",
         y = var) +
    theme_minimal() +
    scale_fill_brewer(palette = "Set2")  
  
  print(p)
}
```

***Step 4***

```{r}

ggplot(z, aes(x = age, y = height, color = gender)) +
  geom_point(alpha = 0.6) +  
  labs(title = "Height vs. Age by Gender",
       x = "Age",
       y = "Height") +
  theme_minimal() +
  scale_color_brewer(palette = "Set1")  


ggplot(z, aes(x = age, y = weight, color = gender)) +
  geom_point(alpha = 0.6) +
  labs(title = "Weight vs. Age by Gender",
       x = "Age",
       y = "Weight") +
  theme_minimal() +
  scale_color_brewer(palette = "Set1")
```

*** Do these variables seem to be related? In what way?***
#There seems to be a positive correlation between height and age, as well as weight and age. As individuals grow older, they tend to become taller and heavier.

***Step 5***

```{r}

numeric_cols <- z %>%
  select(where(is.numeric)) %>%
  select(-id) %>%  
  colnames()

for (var in numeric_cols) {
  
  # Histogram with Density Curve
  p1 <- ggplot(z, aes(x = .data[[var]])) +
    geom_histogram(aes(y = ..density..), bins = 30, fill = "steelblue", alpha = 0.7) +
    geom_density(color = "red", size = 1) +  # Overlay density curve
    labs(title = paste("Histogram of", var),
         x = var,
         y = "Density") +
    theme_minimal()
  
  print(p1)
  
  # Q-Q Plot
  p2 <- ggplot(z, aes(sample = .data[[var]])) +
    stat_qq() +
    stat_qq_line(color = "red") +
    labs(title = paste("Q-Q Plot of", var)) +
    theme_minimal()
  
  print(p2)
}

```
*** Do these variables seem to be related? In what way?***

#zombies_killed and years of education do not have normal distributions.

***Step 6 ***

```{r}

set.seed(42)

sample_z <- z %>%
  slice_sample(n = 50)


numeric_cols <- sample_z %>%
  select(where(is.numeric)) %>%
  select(-id) %>%  
  colnames()

# CI
compute_CI <- function(x) {
  n <- length(x)
  mean_x <- mean(x, na.rm = TRUE)  
  sd_x <- sd(x, na.rm = TRUE)  
  se_x <- sd_x / sqrt(n)
  t_crit <- qt(0.975, df = n - 1)
  
  lower_CI <- mean_x - t_crit * se_x
  upper_CI <- mean_x + t_crit * se_x
  
  return(tibble(
    Mean = mean_x,
    Sample_SD = sd_x,
    Standard_Error = se_x,
    Lower_CI = lower_CI,
    Upper_CI = upper_CI
  ))
}


ci_results <- sample_z %>%
  summarize(across(all_of(numeric_cols), compute_CI, .names = "{.col}"))

print(ci_results)



```

***Step 7***
```{r}

library(tidyverse)

set.seed(42)


numeric_cols <- z %>%
  select(where(is.numeric)) %>%
  select(-id) %>%  
  colnames()


get_sample_means <- function() {
  sample_z <- z %>%
    slice_sample(n = 50)  

  sample_means <- sample_z %>%
    summarize(across(all_of(numeric_cols), mean, na.rm = TRUE))  

  return(sample_means)
}


sampling_distribution <- map_dfr(1:200, ~get_sample_means())


sampling_sum_stats <- sampling_distribution %>%
  summarise(across(everything(), sd))


print(head(sampling_distribution))


print(sampling_sum_stats)


```

***What are the means and standard deviations of the sampling distribution for each variable? How do the standard deviations of the sampling distribution for each variable compare to the standard errors estimated from your first sample of size 50?***

#Based on the data comparison, small differences appeared. However, the SD values are close to the SE values, indicating that SE is a good estimate of the variability in sample means.

***Step 8***
```{r}

sampling_distribution_long <- sampling_distribution %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Sample_Mean")


ggplot(sampling_distribution_long, aes(x = Sample_Mean, fill = Variable)) +
  geom_histogram(bins = 30, alpha = 0.7, position = "identity") +
  facet_wrap(~ Variable, scales = "free", ncol = 2) +
  labs(title = "Sampling Distributions of Means for Each Variable",
       x = "Sample Mean",
       y = "Frequency") +
  theme_minimal() +
  theme(legend.position = "none")


```

***What do they look like? Are they normally distributed? What about for those variables that you concluded were not originally drawn from a normal distribution?***

#The distributions for Height, Weight, and Age showed a normal distribution. Zombies Killed and Years of Education show slight skewness but still approximate normality due to the Central Limit Theorem (CLT). According to the CLT, if a variable is normally distributed in the population, its sample mean distribution will also be normal. If the sample size is large enough, its sample mean distribition tends to become normal. The originally skewed variables, Zombies Killed and Years of Education, now show a more normal shape compared to their original distribution. 

***Step 9***
```{r}
calculate_CI_from_sampling_dist <- function(variable) {
  
  sample_means <- sampling_distribution_long %>%
    filter(Variable == variable) %>%
    pull(Sample_Mean)
  
  
  lower_CI <- quantile(sample_means, 0.025)
  upper_CI <- quantile(sample_means, 0.975)
  
  return(tibble(
    Variable = variable,
    Lower_CI = lower_CI,
    Upper_CI = upper_CI
  ))
}

ci_from_sampling_distribution <- map_dfr(numeric_cols, calculate_CI_from_sampling_dist)


print(ci_from_sampling_distribution)


```


***Step 10***
```{r}
bootstrap_CI <- function(variable) {
  
  original_data <- sample_z[[variable]]
  
  bootstrap_means <- replicate(1000, {
    sample(original_data, size = length(original_data), replace = TRUE) %>%
      mean(na.rm = TRUE)
  })
  
  
  lower_CI <- quantile(bootstrap_means, 0.025)
  upper_CI <- quantile(bootstrap_means, 0.975)
  
  return(tibble(
    Variable = variable,
    Lower_CI = lower_CI,
    Upper_CI = upper_CI
  ))
}


bootstrap_CIs <- map_dfr(numeric_cols, bootstrap_CI)


print(bootstrap_CIs)


```

***How does this compare to the CIs generated in Step 9?***

CIs from Step 9 and Step 10 are similar, indicating consistency in the estimation of population means. 
